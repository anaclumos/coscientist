---
title: "توکن‌های خروجی ≠ دانش"
description: بیانیه و روایت شخصی برای سیستم Coscientist
---

## جست‌وجوی شخصی برای یک اسکلت بیرونی شناختی

من، [سانگ‌هیون چو](./sunghyun-cho)، با احترامی عمیق نسبت به دانشنامه‌ها و ایده‌ی یک مخزن یگانه و مقتدر برای دانش بزرگ شدم. در کودکی، با ولع _Encyclopedia Galactica_ را ورق می‌زدم و جهانی را تصور می‌کردم که همه‌ی پروژه‌ها و پژوهش‌هایم بتوانند درون یک مرجع جهانی زندگی کنند. بعدها مقاله‌ی ۱۹۴۵ وانیوار بوش، [As We May Think](./as-we-may-think)، را کشف کردم که [Memex](./memex) را توصیف می‌کرد: آرشیوی که به افراد اجازه می‌دهد سوابق را ذخیره کنند و از طریق مسیرهای تداعی‌گرانه بازیابی‌شان کنند. آن چشم‌انداز مثل یک اسکلت بیرونی شناختی به نظر می‌رسید.

تا زمانی که در قرن ۲۱ کار خودم را آغاز کردم، اینترنت به تقریبِ زمختی از یک Memex جهانی تبدیل شده بود. بااین‌حال چیزی کم بود: اینترنت سوابق جمعی را حفظ می‌کرد، اما نمی‌توانست ذهن فرد را ثبت کند—از جمله زمینه‌ی شخصی، بینش‌های درحال‌تکامل، و ایده‌های زنده. با ابزارهای [second brain](./second-brain) و شیوه‌های [digital garden](./digital-garden) آزمایش کردم، اما دیدم بیش از حد دستی و بیش از حد شکننده‌اند. من یک [digital brain](./digital-brain) برون‌سپاری‌شده می‌خواستم که با اصطکاک حداقلی رشد کند و سازگار شود.

همین دریافت، جرقه‌ی [Project Aldehyde](./project-aldehyde) را زد؛ تلاش من برای ساختن یک اَبَرمجموعه از Memex برای استفاده‌ی شخصی. سال‌ها تکرار و اصلاح در نهایت به مقاله‌ی مه ۲۰۲۲ من با عنوان [Creating Next-gen Digital Brains](./creating-next-gen-digital-brains) انجامید که استدلال می‌کرد اصطکاک دشمن جریان‌های کاری دانشِ شخصی است: بهترین راه مدیریت یک باغ، رسیدگی دائمی نیست، بلکه پرورش یک [digital jungle](./digital-jungle) است که خودسازمان‌دهی می‌کند. باید بتوانید دانش خام را داخل سیستم بریزید و بگذارید خودش آن را سازمان دهد، پیوند بزند، و دوباره روی سطح بیاورد.

تا میانه‌ی ۲۰۲۲، یک نمونه‌ی اولیه با استفاده از یک پایپ‌لاین سایت ایستا از Obsidian به وب پیاده‌سازی کردم و نامش را [Extracranial](./extracranial) گذاشتم. این یک مغز دیجیتال شخصی بود که محتوا را خودکار نمایه‌سازی می‌کرد، بک‌لینک‌ها را پیشنهاد می‌داد، و اجازه می‌داد پست‌های قدیمی مگر آن‌که «همیشه‌سبز» علامت‌گذاری شوند، به‌تدریج فرسوده شوند. این کار مرا از ریزمدیریت پیوندها آزاد کرد و اجازه داد روی نوشتن و فکر کردن تمرکز کنم.

اما هنگام ساختن آن ویکی شخصی، مسئله‌ای بزرگ‌تر خودش را نشان داد: حتی یک Memex شخصیِ بی‌نقص هم کافی نیست اگر محیط معرفتیِ گسترده‌تر مخدوش شده باشد. با فراگیر شدن هوش مصنوعی مولد، پرسش عمیق‌تر از «چطور دانش را ذخیره کنم؟» به «وقتی AI می‌تواند سامانه‌ها را با متنِ باورپذیر غرق کند، چطور جلوی فروپاشیِ راستی‌آزمایی را بگیریم؟» تغییر کرد.

## از مغزهای دیجیتال تا پروتکل‌ها

رسانه‌های سنتی ساختار خطی را تحمیل می‌کنند. دانش در عمل یک شبکه است. «مغز دیجیتال نسل بعد» پاسخ من به این شکاف بود. اصولش ساده بود: ورودیِ بی‌اصطکاک (ثبت ایده‌ها بدون طبقه‌بندی تحمیلی)، سازمان‌دهی خودکار (استنتاج پیوندها به‌صورت الگوریتمی)، تکامل پویا (اجازه دادن به فرسایش دانش یا همیشه‌سبز ماندنش)، محتوای چندوجهی (نمودارها، دموها، رسانه‌ی تعاملی)، و منابع یکپارچه (اتصال یادداشت‌ها به مقاله‌ها، کد، دیتاست‌ها و ارجاعات). پیونددهی دستی هنوز می‌تواند فهم را دقیق‌تر کند، اما باید اختیاری باشد. سیستم باید بارِ اصلی را به دوش بکشد.

تا ۲۰۲۳، با پرسش‌هایی دست‌به‌گریبان بودم که فراتر از یادداشت‌برداری شخصی می‌رفت. محتوای تولیدشده توسط AI خودِ راستی‌آزمایی را تهدید می‌کرد. سناریوی فروپاشی را [Encyclopedia Meltdown](./encyclopedia-meltdown) نامیدم: وقتی AI ابتکارِ نوشتن را به دست می‌گیرد، [responsibility line](./responsibility-line) (خط مسئولیت) محو می‌شود و خطاها از طریق پیوندها خود-تقویت می‌شوند.

راه مقابله یک [epistemic protocol layer](./epistemic-protocol-layer) است؛ یک لایه‌ی قانون اساسی برای سامانه‌های دانشی. تعهدهای اصلی آن عبارت‌اند از: حاکمیت (اقتدار دانش نزد انسانِ [Galarch](./galarch) باقی می‌ماند)، ردیابی‌پذیری (هر ادعا یک خط مسئولیت را حفظ می‌کند)، و اعتبارسنجیِ «اول ردیه» (پیش از پذیرش، با [rebuttal-first search](./rebuttal-first-search) به دنبال شواهدِ نقض بگردید). این لایه همچنین با فشارهایی مانند [model collapse](./model-collapse) و سیلِ [AI slop](./ai-slop) با تحمیل منشأ (provenance) صریح و ورودِ مبتنی بر «صفر اعتماد» (zero-trust) مقابله می‌کند.

## ScienceOps و مقیاس نهادی

زیرساخت دانشِ شخصی، مسئله‌ی راحتی را حل می‌کرد، نه مقیاس نهادی را. جهش بعدی [ScienceOps](./scienceops) بود: به‌کارگیری انضباط عملیات نرم‌افزار (software-operations) در پژوهش علمی از طریق آزمایش‌های قابل‌بازتولید، اتوماسیون، و تکرار سریع، همراه با معرفی نقشِ [natural science engineer](./natural-science-engineer) (مهندس علوم طبیعی). وقتی آزمایش‌ها به پایپ‌لاین تبدیل شوند، نه کارهای یک‌باره، حلقه‌ی بین فرضیه و راستی‌آزمایی می‌تواند به‌طور چشمگیری کوچک شود.

هدف بزرگ‌تر یک «GitHub برای دانشمندان» است که آزمایش‌ها را مانند کد تلقی می‌کند: نسخه‌بندی‌شده، تکرارپذیر، و قابل ممیزی. این همان زمینه‌ی عملیاتی است که موتور شناختی‌ای مثل [Coscientist](./coscientist) را طلب می‌کند.

## Coscientist: معماری، عاملیت، و نقشه‌ی راه

[Coscientist](./coscientist) سیستمی است که این رشته‌ها را به هم می‌بافد. این یک معماری چندعامله‌ی LLM است که طراحی شده تا به‌جای یک موتور پاسخِ واحد، مانند یک همکار پژوهشی عمل کند. حلقه‌ی داخلی آن «پیشنهاد»، «نقد»، «رتبه‌بندی»، و «اصلاح» را از هم جدا می‌کند، با یک لایه‌ی فرابررسی (meta-review) که انسجام، ردیابی‌پذیری، و عدم‌قطعیت را کنترل می‌کند.

در لایه‌ی دانش، یک [Dialectical Graph](./dialectical-graph) را نگه می‌دارد که به‌جای متن خام، ادعاها و روابط را ذخیره می‌کند. خروجی روایی به‌عنوان فرافکنیِ یک لایه‌ی استنتاجی در نظر گرفته می‌شود، بنابراین هر گزاره می‌تواند به منابع، بازه‌های شواهد (evidence spans)، و روابط صریح عقب‌گرد کند. این جداسازی از حالت شکستِ «روان اما غیرقابل راستی‌آزمایی» در تولید متعارف جلوگیری می‌کند.

ایمنیِ سنتیِ AI اغلب مسئله را «هم‌ترازی» (alignment) چارچوب‌بندی می‌کند. من بر [cognitive agency preservation](./cognitive-agency-preservation) (حفظ عاملیت شناختی) تأکید می‌کنم: AI باید قضاوت انسانی را تقویت کند، نه جایگزین آن شود. در عمل، یعنی نگه‌داشتن کاربر در نقشِ راستی‌آزما: نشان دادن فرایند، آشکار کردن عدم‌قطعیت، ارائه‌ی فرضیه‌های جایگزین، و پیش‌فرض کردنِ جست‌وجوی ردیه.

Coscientist قرار است نقشه‌ی راهی برای یک زیرساخت معرفتیِ جدید باشد: بی‌اصطکاک اما حاکمیتی، سریع اما پاسخ‌گو، قدرتمند بدون فرسایشِ عاملیت. سه حالت شکست را هدف می‌گیرد: پوسیدگی مغز نهادی (با ارجاع متقاطع و بازبینی خصمانه/آزمون‌گرانه کاهش می‌یابد)، فروپاشی راستی‌آزمایی (با ردیابی‌پذیری و جست‌وجوی ردیه‌ی خودکار کاهش می‌یابد)، و از دست رفتن عاملیت (با شفافیت و حق وتوی انسان کاهش می‌یابد).

چشم‌انداز بلندمدت، شبکه‌ای فدره از نمونه‌های Coscientist در مقیاس‌های شخصی، سازمانی، و عمومی است که دانش اعتبارسنجی‌شده را مبادله می‌کنند و در عین حال حاکمیت محلی را حفظ می‌کنند. اگر مسیر مطالعه می‌خواهید، از [Creating Next-gen Digital Brains](./creating-next-gen-digital-brains) (ابزارهای شخصی) شروع کنید، سپس [Encyclopedia Meltdown](./encyclopedia-meltdown) و [epistemic protocol layer](./epistemic-protocol-layer) (حالت شکست و دفاعش)، و بعد [Dialectical Graph](./dialectical-graph) و [knowledge synthesis](./knowledge-synthesis) (معماری).