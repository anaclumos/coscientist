---
title: KI-Schlonz
description: Minderwertige KI-generierte Inhalte überschwemmen das Internet
---

KI-Schlonz (oder einfach Schlonz) sind mit geringem Aufwand und in hoher Menge produzierte Inhalte, die mit generativen Modellen erstellt werden: Texte, Bilder, Videos und sogar Bücher, die eher auf Durchsatz als auf Bedeutung optimiert sind. Der Begriff übernimmt „Schlonz“ als abwertende Bezeichnung für Output, der billig zu produzieren, aber teuer zu durchsuchen ist; [Merriam-Webster](https://www.merriam-webster.com/) beschreibt ihn als minderwertige digitale Inhalte, die mithilfe von KI in großer Menge produziert werden.

In der Praxis umfasst Schlonz absurde Kurzvideos, unheimlich wirkende Werbebilder, von KI geschriebene Bücher zweifelhafter Originalität, plausibel wirkende Fake News sowie Engagement-Köder, die Tragödien oder Empörung ausnutzen. Sobald das Label existiert, neigt es dazu, sich zu verallgemeinern („Architektur-Schlonz“, „Wortschlonz“) und sich an Verhalten zu heften („Schlonzer“, die standardmäßig generieren, statt nachzudenken).

Das tieferliegende Problem ist epistemisch: Schlonz erhöht das Grundrauschen des Internets, treibt die Kosten der Verifikation in die Höhe und drängt Systeme in eine selbstreferenzielle Drift. In diesem Sinne steht er sowohl in der Nähe von [Model Collapse](./model-collapse) (kontaminierte Trainingsdaten) als auch von [Encyclopedia Meltdown](./encyclopedia-meltdown) (kontaminierte Wissensbasen).