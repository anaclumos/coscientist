---
title: "آؤٹ پٹ ٹوکنز ≠ علم"
description: کوسائنٹسٹ نظام کے لیے منشور اور ذاتی بیانیہ
---

## ایک ادراکی بیرونی ڈھانچے (Cognitive Exoskeleton) کی ذاتی جستجو

میں، [Sunghyun Cho](./sunghyun-cho)، انسائیکلوپیڈیاز کے لیے عقیدت اور علم کے ایک واحد بااختیار ذخیرے (repository) کے تصور کے ساتھ بڑا ہوا۔ بچپن میں میں _Encyclopedia Galactica_ کو کھنگالتا رہتا تھا، اور ایک ایسی دنیا کا تصور کرتا تھا جہاں میرے تمام منصوبے اور تحقیق ایک عالمگیر حوالہ (universal reference) کے اندر رہ سکیں۔ بعد میں مجھے Vannevar Bush کے 1945 کے مضمون [As We May Think](./as-we-may-think) کا پتا چلا، جس میں [Memex](./memex) بیان کیا گیا تھا: ایک ایسا آرکائیو جو افراد کو ریکارڈ محفوظ کرنے اور ان تک ربطی راہوں (associative trails) کے ذریعے رسائی دینے دیتا ہے۔ وہ وژن مجھے ایک ادراکی بیرونی ڈھانچے جیسا محسوس ہوا۔

جب میں نے 21ویں صدی میں اپنا کیریئر شروع کیا، تب تک انٹرنیٹ ایک عالمی Memex کا ایک کھردرا سا عکس بن چکا تھا۔ مگر کچھ کمی تھی: اس نے اجتماعی ریکارڈ تو محفوظ کیے، لیکن فرد کے ذہن کو—جس میں ذاتی سیاق (context)، بدلتی بصیرتیں (insights)، اور زندہ خیالات شامل ہیں—پکڑنے میں ناکام رہا۔ میں نے [second brain](./second-brain) ٹولز اور [digital garden](./digital-garden) طریقوں کے ساتھ تجربہ کیا، مگر وہ بہت زیادہ دستی (manual) اور بہت نازک (brittle) نکلے۔ مجھے ایک بیرونی [digital brain](./digital-brain) چاہیے تھا جو کم سے کم رگڑ (friction) کے ساتھ بڑھتا اور ڈھلتا رہے۔

اسی ادراک نے [Project Aldehyde](./project-aldehyde) کا آغاز کیا—ذاتی استعمال کے لیے Memex کے ایک سپر سیٹ بنانے کی میری کوشش۔ برسوں کی تکرار (iteration) بالآخر میرے مئی 2022 کے مضمون [Creating Next-gen Digital Brains](./creating-next-gen-digital-brains) پر منتج ہوئی، جس نے یہ دلیل دی کہ رگڑ ذاتی علم کے ورک فلو کی دشمن ہے: باغ سنبھالنے کا بہترین طریقہ مسلسل گوڈی (tending) نہیں، بلکہ ایک [digital jungle](./digital-jungle) کو پروان چڑھانا ہے جو خود ترتیب پاتا ہے۔ آپ کو خام علم اندر پھینک دینے کے قابل ہونا چاہیے اور نظام کو اسے منظم کرنے، جوڑنے، اور دوبارہ سامنے لانے دینا چاہیے۔

2022 کے وسط تک، میں نے Obsidian سے ویب تک ایک static-site پائپ لائن استعمال کرتے ہوئے ایک پروٹوٹائپ نافذ کیا اور اسے [Extracranial](./extracranial) نام دیا۔ یہ ایک ذاتی ڈیجیٹل دماغ تھا جو مواد کو خودکار طور پر انڈیکس کرتا، بیک لنکس (backlinks) تجویز کرتا، اور پرانی پوسٹس کو تب تک زوال (decay) کی اجازت دیتا جب تک انہیں evergreen کے طور پر نشان زد نہ کیا جائے۔ اس نے مجھے لنکس کی مائیکرو مینجمنٹ سے آزاد کیا اور مجھے لکھنے اور سوچنے پر توجہ دینے دی۔

لیکن جیسے جیسے میں وہ ذاتی وکی بنا رہا تھا، ایک بڑا مسئلہ سامنے آیا: اگر وسیع تر epistemic ماحول (علمیاتی ماحول) خراب ہو جائے تو ایک بالکل کامل ذاتی Memex بھی کافی نہیں۔ جب تخلیقی AI (generative AI) عام ہونے لگا، تو بنیادی سوال "میں علم کیسے محفوظ کروں؟" سے بدل کر یہ ہو گیا: "جب AI بظاہر قابلِ یقین متن سے نظاموں کو بھر دے تو ہم تصدیق (verification) کو منہدم ہونے سے کیسے بچائیں؟"

## ڈیجیٹل دماغوں سے پروٹوکولز تک

روایتی ذرائع ابلاغ خطی (linear) ساخت نافذ کرتے ہیں۔ عملی طور پر علم ایک نیٹ ورک ہے۔ "next-gen digital brain" اسی خلا کے جواب کے طور پر تھا۔ اس کے اصول سیدھے تھے: رگڑ سے پاک ان پٹ (جبراً taxonomy کے بغیر خیالات محفوظ کرنا)، خودکار تنظیم (الگورتھمی طور پر ربط اخذ کرنا)، متحرک ارتقا (علم کو زوال پذیر یا evergreen رہنے دینا)، کثیر النوع مواد (multimodal content) (ڈایاگرامز، ڈیموز، انٹرایکٹو میڈیا)، اور ہموار ذرائع (seamless sources) (نوٹس کو پیپرز، کوڈ، ڈیٹا سیٹس، اور حوالہ جات سے جوڑنا)۔ دستی لنکنگ پھر بھی فہم کو نکھار سکتی ہے، مگر اسے اختیاری ہونا چاہیے۔ بھاری کام نظام کو کرنا چاہیے۔

2023 تک، میں ایسے سوالات سے دوچار تھا جو ذاتی نوٹ سازی سے آگے نکل جاتے تھے۔ AI سے بنا ہوا مواد خود تصدیق کو خطرے میں ڈال رہا تھا۔ میں نے اس انہدامی منظرنامے کو [Encyclopedia Meltdown](./encyclopedia-meltdown) کہا: جب AI لکھنے کی پہل کرتی ہے تو [responsibility line](./responsibility-line) غائب ہو جاتی ہے اور غلطیاں لنکس کے ذریعے خود کو بڑھاتی چلی جاتی ہیں۔

اس کا توڑ ایک [epistemic protocol layer](./epistemic-protocol-layer) ہے—علمی نظاموں کے لیے ایک آئینی (constitutional) پرت۔ اس کے بنیادی عہد (commitments) یہ ہیں: خودمختاری (sovereignty) (علم کی اتھارٹی انسان [Galarch](./galarch) کے پاس رہتی ہے)، قابلِ سراغی (traceability) (ہر دعوے کے ساتھ responsibility line برقرار رہتی ہے)، اور ردِ دلیل-اول (rebuttal-first) توثیق (validation) (قبول کرنے سے پہلے جوابی شواہد ڈھونڈنے کے لیے [rebuttal-first search](./rebuttal-first-search) استعمال کرنا)۔ یہ پرت [model collapse](./model-collapse) اور [AI slop](./ai-slop) کے سیلاب جیسے دباؤ کو بھی واضح ماخذیت (provenance) اور زیرو ٹرسٹ (zero-trust) انجیestion نافذ کر کے سنبھالتی ہے۔

## ScienceOps اور ادارہ جاتی پیمانہ

ذاتی علم کا انفراسٹرکچر سہولت تو حل کرتا ہے، ادارہ جاتی پیمانہ نہیں۔ اگلی جست [ScienceOps](./scienceops) تھی: قابلِ تکرار تجربات (reproducible experiments)، آٹومیشن، اور تیز iteration کے ذریعے سائنسی تحقیق پر سافٹ ویئر-آپریشنز (software-operations) کی نظم و ضبط (discipline) لاگو کرنا، اور ساتھ ہی [natural science engineer](./natural-science-engineer) کے کردار کا تعارف۔ جب تجربات one-offs کے بجائے پائپ لائنز بن جائیں تو مفروضے (hypothesis) اور تصدیق کے درمیان لوپ نمایاں طور پر سکڑ سکتا ہے۔

بڑا مقصد سائنس دانوں کے لیے ایک "GitHub" ہے جو تجربات کو کوڈ کی طرح ٹریٹ کرے: ورژنڈ (versioned)، دہرائے جانے کے قابل (repeatable)، اور آڈٹ ایبل (auditable)۔ یہی وہ آپریشنل سیاق ہے جو [Coscientist](./coscientist) جیسے ادراکی انجن کا تقاضا کرتا ہے۔

## Coscientist: معماری، ایجنسی، اور بلیوپرنٹ

[Coscientist](./coscientist) وہ نظام ہے جو ان دھاگوں کو یکجا کرتا ہے۔ یہ ایک کثیر-ایجنٹ LLM معماری (architecture) ہے، جسے ایک واحد جواب دینے والے انجن کے بجائے تحقیق کے معاون (research collaborator) کے طور پر کام کرنے کے لیے ڈیزائن کیا گیا ہے۔ اس کا اندرونی لوپ تجویز (proposal)، تنقید (critique)، درجہ بندی (ranking)، اور بہتری (refinement) کو الگ کرتا ہے، اور ایک meta-review پرت ہم آہنگی (coherence)، قابلِ سراغی، اور غیر یقینی (uncertainty) کو چیک کرتی ہے۔

علم کی پرت میں، یہ ایک [Dialectical Graph](./dialectical-graph) برقرار رکھتا ہے جو خام متن کے بجائے دعووں (claims) اور تعلقات (relations) کو ذخیرہ کرتا ہے۔ بیانیہ آؤٹ پٹ (narrative output) کو استدلالی پرت (inference layer) کی ایک پروجیکشن سمجھا جاتا ہے، لہٰذا ہر بیان اپنے ذرائع، شواہد کے حصّوں (evidence spans)، اور واضح تعلقات تک واپس ٹریک کر سکتا ہے۔ یہ جداسازی روایتی جنریشن کی "ہموار مگر ناقابلِ تصدیق" ناکامی سے بچاتی ہے۔

روایتی AI سیفٹی اکثر مسئلے کو alignment کے طور پر پیش کرتی ہے۔ میں [cognitive agency preservation](./cognitive-agency-preservation) پر زور دیتا ہوں: AI کو انسانی فیصلہ سازی کو مضبوط کرنا چاہیے، اس کی جگہ نہیں لینی چاہیے۔ عملی طور پر اس کا مطلب یہ ہے کہ صارف کو verifier کے کردار میں رکھا جائے: کام دکھانا (showing work)، غیر یقینی کو نمایاں کرنا، متبادل مفروضات پیش کرنا، اور جوابی دلیل ڈھونڈنے کو ڈیفالٹ بنانا۔

Coscientist کو ایک نئے epistemic انفراسٹرکچر کے بلیوپرنٹ کے طور پر سوچا گیا ہے: رگڑ سے پاک مگر خودمختار، تیز مگر جواب دہ، طاقتور مگر ایجنسی کو کھوکھلا کیے بغیر۔ یہ تین ناکامی طریقوں (failure modes) کو ہدف بناتا ہے: ادارہ جاتی brain rot (cross-referencing اور adversarial review کے ذریعے کم کیا گیا)، تصدیق کا انہدام (traceability اور خودکار rebuttal search کے ذریعے کم کیا گیا)، اور ایجنسی کا زیاں (شفافیت اور انسانی veto کے ذریعے کم کیا گیا)۔

طویل مدتی وژن یہ ہے کہ ذاتی، تنظیمی، اور عوامی پیمانوں پر Coscientist کی مثالوں (instances) کا ایک وفاقی نیٹ ورک ہو جو مقامی خودمختاری برقرار رکھتے ہوئے توثیق شدہ علم کا تبادلہ کرے۔ اگر آپ پڑھنے کا ایک راستہ چاہتے ہیں تو [Creating Next-gen Digital Brains](./creating-next-gen-digital-brains) (ذاتی ٹولنگ) سے شروع کریں، پھر [Encyclopedia Meltdown](./encyclopedia-meltdown) اور [epistemic protocol layer](./epistemic-protocol-layer) (ناکامی کا طریقہ اور اس کا دفاع)، پھر [Dialectical Graph](./dialectical-graph) اور [knowledge synthesis](./knowledge-synthesis) (معماری)۔