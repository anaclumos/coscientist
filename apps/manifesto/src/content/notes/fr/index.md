---
title: "Les tokens de sortie ≠ la connaissance"
description: Manifeste et récit personnel pour le système Coscientist
---

## Une quête personnelle pour un exosquelette cognitif

Moi, [Sunghyun Cho](./sunghyun-cho), j’ai grandi avec une révérence pour les encyclopédies et l’idée d’un dépôt unique et faisant autorité de la connaissance. Enfant, je dévorais _Encyclopedia Galactica_, en imaginant un monde où tous mes projets et mes recherches pourraient vivre à l’intérieur d’une référence universelle. Plus tard, j’ai découvert l’essai de 1945 de Vannevar Bush [As We May Think](./as-we-may-think), qui décrivait le [Memex](./memex) : une archive permettant aux individus de stocker des documents et de les retrouver via des chemins associatifs. Cette vision ressemblait à un exosquelette cognitif.

Au moment où j’ai commencé ma propre carrière au XXIe siècle, Internet était devenu une approximation grossière d’un Memex mondial. Pourtant, il manquait quelque chose : il préservait les archives collectives mais ne parvenait pas à capturer l’esprit de l’individu — y compris le contexte personnel, les intuitions qui évoluent et les idées vivantes. J’ai expérimenté des outils de [second brain](./second-brain) et des pratiques de [digital garden](./digital-garden), pour découvrir qu’ils étaient trop manuels et trop fragiles. Je voulais un [cerveau numérique](./digital-brain) externalisé, capable de croître et de s’adapter avec un minimum de friction.

Cette prise de conscience a lancé [Project Aldehyde](./project-aldehyde), ma tentative de construire un sur-ensemble du Memex pour un usage personnel. Des années d’itérations ont culminé dans mon essai de mai 2022 [Creating Next-gen Digital Brains](./creating-next-gen-digital-brains), qui soutenait que la friction est l’ennemie des flux de travail de connaissance personnelle : la meilleure façon de gérer un jardin n’est pas de l’entretenir constamment, mais de cultiver une [jungle numérique](./digital-jungle) qui s’auto-organise. Vous devriez pouvoir y jeter de la connaissance brute et laisser le système l’organiser, la relier et la faire réémerger.

À la mi-2022, j’ai implémenté un prototype en utilisant un pipeline de site statique d’Obsidian vers le web et je l’ai nommé [Extracranial](./extracranial). C’était un cerveau numérique personnel qui indexait automatiquement le contenu, suggérait des liens entrants (backlinks) et laissait les anciens billets se dégrader, sauf s’ils étaient marqués comme pérennes (evergreen). Il m’a libéré de la micro-gestion des liens et m’a permis de me concentrer sur l’écriture et la réflexion.

Cependant, à mesure que je construisais ce wiki personnel, un problème plus vaste est apparu : même un Memex personnel parfait ne suffit pas si l’environnement épistémique au sens large est compromis. À mesure que l’IA générative devenait omniprésente, la question profonde s’est déplacée de « comment stocker la connaissance ? » vers « comment empêcher la vérification de s’effondrer quand l’IA peut inonder les systèmes de texte plausible ? »

## Des cerveaux numériques aux protocoles

Les médiums traditionnels imposent une structure linéaire. La connaissance, en pratique, est un réseau. Le « cerveau numérique de nouvelle génération » était ma réponse à cet écart. Ses principes étaient simples : saisie sans friction (capturer des idées sans taxonomie imposée), organisation automatisée (inférer les connexions de façon algorithmique), évolution dynamique (laisser la connaissance se dégrader ou rester pérenne), contenu multimodal (diagrammes, démos, médias interactifs) et sources intégrées de manière fluide (relier les notes aux articles, au code, aux jeux de données et aux références). Le liage manuel peut toujours affiner la compréhension, mais il devrait être optionnel. Le système devrait faire l’essentiel du travail.

En 2023, je me débattais avec des questions qui dépassaient la prise de notes personnelle. Le contenu généré par l’IA menaçait la vérification elle-même. J’ai appelé ce scénario d’effondrement [Encyclopedia Meltdown](./encyclopedia-meltdown) : lorsque l’IA prend l’initiative d’écrire, la [responsibility line](./responsibility-line) disparaît et les erreurs s’auto-amplifient via les liens.

La contre-mesure est une [couche de protocole épistémique](./epistemic-protocol-layer), une couche constitutionnelle pour les systèmes de connaissance. Ses engagements centraux sont la souveraineté (l’autorité sur la connaissance reste chez l’humain [Galarch](./galarch)), la traçabilité (chaque affirmation conserve une responsibility line) et la validation « réfutation d’abord » (utiliser la [rebuttal-first search](./rebuttal-first-search) pour rechercher des contre-preuves avant acceptation). Cette couche répond aussi à des pressions comme le [model collapse](./model-collapse) et le déluge d’[AI slop](./ai-slop) en imposant une provenance explicite et une ingestion en zéro confiance (zero-trust).

## ScienceOps et l’échelle institutionnelle

L’infrastructure de connaissance personnelle résolvait la commodité, pas l’échelle institutionnelle. Le saut suivant était [ScienceOps](./scienceops) : appliquer la discipline des opérations logicielles à la recherche scientifique via des expériences reproductibles, l’automatisation et des itérations rapides, tout en introduisant le rôle du [natural science engineer](./natural-science-engineer). Quand les expériences deviennent des pipelines plutôt que des coups isolés, la boucle entre hypothèse et vérification peut se réduire drastiquement.

L’objectif plus large est un « GitHub pour les scientifiques » qui traite les expériences comme du code : versionnées, répétables et auditables. C’est le contexte opérationnel qui exige un moteur cognitif comme [Coscientist](./coscientist).

## Coscientist : architecture, agentivité et plan directeur

[Coscientist](./coscientist) est le système qui synthétise ces fils. C’est une architecture LLM multi-agents conçue pour fonctionner comme un collaborateur de recherche plutôt que comme un moteur de réponses unique. Sa boucle interne sépare proposition, critique, classement et affinage, avec une couche de méta-revue qui vérifie la cohérence, la traçabilité et l’incertitude.

Au niveau de la connaissance, il maintient un [Dialectical Graph](./dialectical-graph) qui stocke des affirmations et des relations plutôt que du texte brut. La sortie narrative est traitée comme une projection d’une couche d’inférence, de sorte que chaque énoncé peut remonter jusqu’aux sources, aux segments de preuve (evidence spans) et aux relations explicites. Cette séparation évite le mode d’échec « fluide mais invérifiable » de la génération conventionnelle.

La sécurité de l’IA traditionnelle cadre souvent le problème comme un alignement. J’insiste sur la [préservation de l’agentivité cognitive](./cognitive-agency-preservation) : l’IA doit renforcer le jugement humain, pas le remplacer. Concrètement, cela signifie garder l’utilisateur dans le rôle du vérificateur : montrer le raisonnement, faire remonter l’incertitude, présenter des hypothèses alternatives et faire de la recherche de réfutation le comportement par défaut.

Coscientist est pensé comme un plan directeur pour une nouvelle infrastructure épistémique : sans friction mais souveraine, rapide mais responsable, puissante sans éroder l’agentivité. Il cible trois modes d’échec : la pourriture cérébrale institutionnelle (atténuée par le recoupement et la revue adversariale), l’effondrement de la vérification (atténué par la traçabilité et la recherche de réfutation automatisée) et la perte d’agentivité (atténuée par la transparence et le veto humain).

La vision à long terme est un réseau fédéré d’instances Coscientist à des échelles personnelle, organisationnelle et publique, qui échangent de la connaissance validée tout en préservant la souveraineté locale. Si vous voulez un parcours de lecture, commencez par [Creating Next-gen Digital Brains](./creating-next-gen-digital-brains) (outillage personnel), puis [Encyclopedia Meltdown](./encyclopedia-meltdown) et la [couche de protocole épistémique](./epistemic-protocol-layer) (le mode d’échec et sa défense), puis [Dialectical Graph](./dialectical-graph) et la [synthèse de connaissance](./knowledge-synthesis) (l’architecture).